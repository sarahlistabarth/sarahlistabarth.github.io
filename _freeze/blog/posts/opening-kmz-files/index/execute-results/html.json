{
  "hash": "89148cecf4790eee0c33047e116c491d",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: Sarah Zeller\ntitle: Opening `.kmz` files\ndate: \"2024-05-27\"\nimage: \"landfills.PNG\"\ncategories: [code, spatial formats]\ncitation:\n  url: https://sarahzeller.github.io/blog/posts/opening-kmz-files/\n\nformat:\n  html:\n    toc: true\n\nexecute:\n  warning: false\n  \neditor: \n  markdown:\n    wrap: sentence\n---\n\n\nWhen working with spatial data, one thing I've noticed is: there's a lot of obscure data formats.\nAnd with every one of them, it takes me a while to figure out how to handle them in `R`.\nSo I decided to make a series of blog posts on how to handle some of the spatial formats I've come across.\n\nThis post is on `.kmz` files.\nIf you're working with Google Earth Pro, this is the format your vector files will be exported in.\nRecently, I've worked quite a bit with Google Earth Pro to collect data on landfills by hand.\nYou'll find an example `.kmz` file [here](https://sarahzeller.github.io/assets/Agbogbloshie.kmz).\n\n# TL;DR\n\nFor a `.kmz` file, follow these steps:\n\n1.  Unzip the `.kmz`, e.g. using `archive::archive_extract`\n2.  Read in the resulting `.kml` file using `sf` or `terra`\n3.  Make sure you only have the geometry type you want -- (multi)polygons.\n\n# Setup\n\nLet's start by loading the necessary libraries.\nWe'll need `archive` to unpack our `.kmz` file.\nWith `sf`, we can then read the corresponding file in.\n`dplyr` will help us wrangle the data once they're read in.\nWith `ggplot2`, we can visualize our data.\n`units` helps wrangling with different area units.\n`unglue` is a package that helps us extract information from strings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(archive)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(units)\nlibrary(unglue)\n```\n:::\n\n\nNow, let's download our file.\nFor this, we use the URL I've mentioned before.\nAlso, we're creating a temporary file into which we load this file -- `kmz_path`.\nWatch out, though: it's a binary file, so we need to add the corresponding argument to the function `download.file`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkmz_url <- \"https://github.com/sarahzeller/sarahzeller.github.io/blob/main/assets/Agbogbloshie.kmz\"\n\nkmz_path <- tempfile(fileext = \".kmz\")\ndownload.file(\n  url = kmz_url,\n  destfile = kmz_path,\n  # it's a binary file\n  mode = \"wb\")\n```\n:::\n\n\n# Unzipping the `.kmz` to `.kml`\n\nThe first step is to unzip our `.kmz`, which hides `.kml` files underneath.\nIn our simple case, it's just a single `.kml` file.\nWe can use the `archive_extract` command for this.\nI'm using temp files here, but feel free to exchange them for your own file paths.\nIn the end, we're checking out everything that was zipped up.\nIn this case, it's just a single file: `doc.kml`.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkml_path <- tempfile()\n\narchive_extract(archive = kmz_path,\n                dir = kml_path)\n\n# check out the contents\nkml_path |> list.files()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"doc.kml\"\n```\n\n\n:::\n:::\n\n\n# Read in the `.kml` file\n\nNow that we've gotten to our `.kml` file, let's read it into `R`.\nSince this is not raster, but vector data, we're using the library `sf` for this task.\nWe're working with a `temp` file, so we need the `list.files` function to find out exactly where the file is that we're interested in.\n\nNow that we've read it in, we can see that there are two different types of geometries in this file:\n\n-   point geometry (row 1)\n-   multypolygon geometries (row 2--3)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie <- kml_path |> \n  list.files(full.names = TRUE) |> \n  read_sf()\n\nagbogbloshie |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XYZ\nBounding box:  xmin: -0.2311228 ymin: 5.54208 xmax: -0.2246721 ymax: 5.556922\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 3\n  Name                    Description                                   geometry\n  <chr>                   <chr>                                   <GEOMETRY [°]>\n1 Agbogbloshie            \"\"                     POINT Z (-0.2264589 5.548876 0)\n2 Agbogbloshie_02_2020    \"\"          MULTIPOLYGON Z (((-0.2311228 5.554326 0, …\n3 Agbogbloshie_10_2018    \"\"          MULTIPOLYGON Z (((-0.2304394 5.552348 0, …\n4 Agblogbloshie 10_2016   \"\"          MULTIPOLYGON Z (((-0.2292498 5.550126 0, …\n5 Agbogbloshie_10_2018_02 \"\"          MULTIPOLYGON Z (((-0.229426 5.553367 0, -…\n6 Agbogbloshie_10_2018_03 \"\"          MULTIPOLYGON Z (((-0.2264083 5.550984 0, …\n```\n\n\n:::\n:::\n\n\n# Sorting the `.kml` content\n\nWe've seen that there's two different types of geometries in this `.kml` file.\nLet's unpack these into two objects.\nTo do this, we use the geometry types of each row, and simply filter for points and multipolygons.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_point <- agbogbloshie |> \n  filter(st_geometry_type(geometry) == \"POINT\")\n\nagbogbloshie_polygon <- agbogbloshie |> \n  filter(st_geometry_type(geometry) == \"MULTIPOLYGON\")\n```\n:::\n\n\n# Manipulating the data\n\nNow that we've gotten the data into a format we can work with, let's add some information.\nThe first thing is to put the information contained in the `Name` column into a readable format.\nNext thing, we want to compute the area of our polygons.\n\n## Extracting information from the `Name`\n\nWhen we check out our `agbogbloshie_polygon` data frame, we can see that there's information contained in the `Name` column, specifically: the year for which the polygon shape is valid.\nSo let's extract that `numeric` information from the `character` column!\nBecause the description is quite long and has much information included -- and it's always formatted the same way --, we'll use the `unglue` package to extract the information.\nAlso, the landfill is misspelt in some cases, so we need to account for that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_polygon <- agbogbloshie_polygon |> \n  unglue_unnest(Name, \n                patterns = c(\"{landfill_name}_{month}_{year}_{polygon_no}\",\n                             \"{landfill_name}_{month}_{year}\",\n                             \"{landfill_name} {month}_{year}\"),\n                remove = FALSE) |> \n  mutate(landfill_name = case_match(landfill_name,\n                                    \"Agblogbloshie\" ~ \"Agbogbloshie\",\n                                    \"Agbogbgloshie\" ~ \"Agbogbloshie\",\n                                    .default = \"Agbogbloshie\"))\n\nagbogbloshie_polygon\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 8 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XYZ\nBounding box:  xmin: -0.2311228 ymin: 5.54208 xmax: -0.2246721 ymax: 5.556922\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n# A tibble: 8 × 7\n  Name                     Description landfill_name month year  polygon_no\n* <chr>                    <chr>       <chr>         <chr> <chr> <chr>     \n1 Agbogbloshie_02_2020     \"\"          Agbogbloshie  02    2020  <NA>      \n2 Agbogbloshie_10_2018     \"\"          Agbogbloshie  10    2018  <NA>      \n3 Agblogbloshie 10_2016    \"\"          Agbogbloshie  10    2016  <NA>      \n4 Agbogbloshie_10_2018_02  \"\"          Agbogbloshie  10    2018  02        \n5 Agbogbloshie_10_2018_03  \"\"          Agbogbloshie  10    2018  03        \n6 Agbogbgloshie_02_2020_02 \"\"          Agbogbloshie  02    2020  02        \n7 Agbogbloshie_02_2020_03  \"\"          Agbogbloshie  02    2020  03        \n8 Agbogbloshie_10_2016_02  \"\"          Agbogbloshie  10    2016  02        \n# ℹ 1 more variable: geometry <MULTIPOLYGON [°]>\n```\n\n\n:::\n:::\n\n\nLet's use this information to plot the landfill in the two different years!\nSeems like the landfill grew quite a bit in between.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = agbogbloshie_polygon) +\n  facet_wrap(~year) +\n  geom_sf(data = agbogbloshie_point) +\n  theme_void() +\n  ggspatial::annotation_scale()\n```\n\n::: {.cell-output-display}\n![Agbogbloshie landfill over time](index_files/figure-html/fig-landfill-1.png){#fig-landfill width=672}\n:::\n:::\n\nThis looks good!\nHowever, we can see that the landfills consist of multiple polygons.\nLet's get them together.\n\n## Summarizing into one polygon\n\nIn every year, we have more than one polygon.\nWe want to collapse these into a single multipolygon.\nFor that, we need to summarize them by `year` and `landfill`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_polygon <- agbogbloshie_polygon |> \n  st_zm() |> \n  st_transform(crs = \"ESRI:54009\") |> \n  st_make_valid() |> \n  # summarize geometry into multipolygons\n  group_by(landfill_name, year, month) |> \n  summarize() |> \n  ungroup()\n```\n:::\n\n\n\n\n## Calculating area\n\nAs a next step, let's calculate the area of these polygons.\nAfter all, it's interesting to see if this landfill shrinks or grows!\n\nFor now, our data are *unprojected*, though.\nWe can check this by getting the coordinate reference system (CRS) of our data.\nThe output is very long and includes a lot of information, but we only need to focus on the first line, the *User input*.\nThe next lines show the corresponding *well-known text (wkt)*, which details exactly how the CRS works.\nWe can see here that the CRS is still *WGS 84*, which means -- unprojected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(agbogbloshie)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n```\n\n\n:::\n:::\n\n\nHowever, we know that the world is shaped like a potato, and that these unprojected data are biased.\nTo correct for this, we first need to project the data into a CRS that's accurate for that world region when it comes to area -- we also call this area-preserving projection.\nThe official CRS for Ghana, where this landfill is located, has the EPSG code `2136`.\nOnce we've projected the polygons, we can easily calculate the area with the `sf` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_polygon <- agbogbloshie_polygon |> \n  st_transform(crs = \"epsg:2136\") |> \n  mutate(area = st_area(geometry)) \n\nagbogbloshie_polygon\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 3 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1179342 ymin: 316685.8 xmax: 1181692 ymax: 322068\nProjected CRS: Accra / Ghana National Grid\n# A tibble: 3 × 5\n  landfill_name year  month                                      geometry   area\n* <chr>         <chr> <chr>                                <MULTIPOLYGON>  [m^2]\n1 Agbogbloshie  2016  10    (((1180085 320017.8, 1180468 319802.8, 11805… 2.41e5\n2 Agbogbloshie  2018  10    (((1180357 319898.9, 1180372 319891.8, 11803… 2.94e5\n3 Agbogbloshie  2020  02    (((1179921 320055.5, 1179936 320041.3, 11799… 2.56e5\n```\n\n\n:::\n:::\n\n\nYou'll notice that the `area` column has a specific format: it's a `unit`.\nThis package makes it easy to convert values from one unit into another.\nLet's see how we can convert the area into hectares.\nAfterwards, let's drop the `unit` because we have the data in the final shape we want them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_polygon <- agbogbloshie_polygon |> \n  mutate(area_ha = set_units(area, \"ha\") |> drop_units())\n```\n:::\n\n\nAnd there we have it, a data frame with the attributes that we need!\nLet's check out the area in comparison.\nWe see that there's not that much difference!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = agbogbloshie_polygon) +\n  geom_col(aes(x = year |> as.character(), y = area_ha)) +\n  coord_flip() +\n  labs(y = \"Area (ha)\",\n       x = \"\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Agbogbloshie landfill area over time](index_files/figure-html/fig-bar-plot-1.png){#fig-bar-plot width=672}\n:::\n:::\n\n\n# Alternative using `terra`\n\nIf you prefer working with `terra`, e.g. because you need to combine your polygon data with raster data, you can of course also read in the `.kml` data.\nSince this is not the focus of this post, here's a quick walk-through.\n\n::: callout-note\n`vect` just drops the point geometry.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nlibrary(tidyterra)\nlibrary(tidyverse)\n\nagbogbloshie_terra <- kml_path |>  \n  # select first file there\n  list.files(full.names = TRUE) |> \n  pluck(1) |> \n  # read in with terra\n  vect() |> \n  project(\"epsg:2136\") %>%\n  # expanse is an odd function where we need to input the above again, that's\n  # why I added the tidyverse pipe and the dot.\n  mutate(area = expanse(., unit = \"ha\"))\n```\n:::\n\nLastly, let's account for the misspelt names in the `landfill_name` column.\nAlso, let's sum the area per year.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagbogbloshie_terra_clean <- agbogbloshie_terra |> \n  as.data.frame() |> \n  unglue_unnest(Name, \n                patterns = c(\"{landfill_name}_{month}_{year}_{polygon_no}\",\n                             \"{landfill_name}_{month}_{year}\",\n                             \"{landfill_name} {month}_{year}\"),\n                remove = FALSE) |> \n  mutate(landfill_name = case_match(landfill_name,\n                                    \"Agblogbloshie\" ~ \"Agbogbloshie\",\n                                    \"Agbogbgloshie\" ~ \"Agbogbloshie\",\n                                    .default = \"Agbogbloshie\")) |> \n  group_by(landfill_name, year) |> \n  summarize(area_ha = sum(area)) |> \n  ungroup()\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}