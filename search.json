[
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Software",
    "section": "",
    "text": "donutsR \n        \n        Provides a set of functions to implement donut analyses in R â€“\nfor when you're unsure which distance to a point of interest still counts as treated.\n\n\n        \n            \n            \n                \n                     GitHub\n                \n            \n            \n            \n            \n                \n                     Documentation\n                \n            \n            \n        \n    \n    \n    \n        \n            tud \n        \n        Quarto template in TUD corporate design for presentations and extendes abstracts â€“\nfor both typst and latex output.\n\n\n        \n            \n            \n                \n                     GitHub\n                \n            \n            \n            \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/reading-csv-with-2row-colnames/index.html",
    "href": "blog/posts/reading-csv-with-2row-colnames/index.html",
    "title": "Reading a csv file with 2-row column names",
    "section": "",
    "text": "I recently wanted to check out election results from the last German Bundestag election, and read them into R. The data was saved in a csv file â€“ so far, so good. But the column names were spread over two rows. ðŸ˜±\nThis means Iâ€™m losing valuable information if Iâ€™m only reading the first row of column names. Additionally, the types of the rows get messed up, since the second row of the column names is read as data â€“ specifically, character data.\nSo, I wanted to combine both rows of column names into one. Hereâ€™s how I did it in R."
  },
  {
    "objectID": "blog/posts/reading-csv-with-2row-colnames/index.html#reading-the-first-row",
    "href": "blog/posts/reading-csv-with-2row-colnames/index.html#reading-the-first-row",
    "title": "Reading a csv file with 2-row column names",
    "section": "Reading the first row",
    "text": "Reading the first row\nThereâ€™s probably many ways to do this, but I decided to go for the following approach:\n\nread in the csv file starting at the first column name row\nclean the column names\nstore the column names in a variable\n\nTo read in the first row of column names, we can use the read.csv2() function. Weâ€™ll skip the first three rows (which only contain metadata) and read in only one row, since we donâ€™t need the content for now. Then, weâ€™ll clean the column names with janitor::clean_names() to make sure that theyâ€™re formatted like we want them to. Lastly, Iâ€™m removing the numbers that are attached at the end since some of the variable names so far are not unique (since theyâ€™re still missing the second row).\n\ncolnames_row1 &lt;- read.csv2(temp_file, skip = 4, nrows = 1) |&gt;\njanitor::clean_names() |&gt; \n  colnames() |&gt; \n  gsub(\"_[[:digit:]].*\", \"\", x = _)"
  },
  {
    "objectID": "blog/posts/reading-csv-with-2row-colnames/index.html#reading-both-column-names",
    "href": "blog/posts/reading-csv-with-2row-colnames/index.html#reading-both-column-names",
    "title": "Reading a csv file with 2-row column names",
    "section": "Reading both column names",
    "text": "Reading both column names\nWe could repeat this procedure for the second row of column names. However, itâ€™s better to create a function for this case. We simply take the pipeline from before and put it into a function.\n\nread_colnames &lt;- function(path, skip_rows = 4, no_rows = 1) {\n  path |&gt; \n    read.csv2(skip = skip_rows, nrows = no_rows) |&gt; \n    janitor::clean_names() |&gt; \n    colnames() |&gt; \n    gsub(\"_[[:digit:]].*\", \"\", x = _)\n}"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html",
    "href": "blog/posts/opening-nc-files/index.html",
    "title": "Opening .nc files",
    "section": "",
    "text": "When working with raster data, one thing Iâ€™ve noticed is: thereâ€™s a lot of obscure data formats. And with every one of them, it takes me a while to figure out how to handle them in R. So I decided to make a series of blog posts on how to handle some of the raster formats Iâ€™ve come across.\nThe first one are .nc files, also known as netCDF. From what Iâ€™ve learned, they usually have three layers:\nHowever, the order of these three layers varies, which means youâ€™ll have to get acquainted with your data first. So:"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#open-nc-file",
    "href": "blog/posts/opening-nc-files/index.html#open-nc-file",
    "title": "Opening .nc files",
    "section": "Open nc file",
    "text": "Open nc file\nThe first thing we do is have a look at the variable names (theyâ€™re saved under var in the weather list). Letâ€™s also check out their names, which is saved under longname in this ncd4 format. Additionally, letâ€™s find out their respective dimensions, saved under size.\n\nraster &lt;- raster_path |&gt; nc_open()\n\nraster |&gt; \n  pluck(\"var\") |&gt; \n  map_df(~ .x[c(\"longname\", \"size\")] |&gt; as.character()) |&gt; \n  # you could stop here, but I wanted a nice display\n  t() |&gt; \n  data.frame() |&gt; \n  tibble::rownames_to_column() |&gt; \n  setNames(c(\"variable\", \"name\", \"dimension\")) |&gt; \n  kableExtra::kbl()\n\n\n\n\nvariable\nname\ndimension\n\n\n\n\ntime_bnds\ntime_bnds\nc(2, 365)\n\n\nlon\nLongitude Of Cell Center\nc(240, 220)\n\n\nlat\nLatitude Of Cell Center\nc(240, 220)\n\n\nx_bnds\nx_bnds\nc(2, 240)\n\n\ny_bnds\ny_bnds\nc(2, 220)\n\n\ncrs_HYRAS\nDWD HYRAS ETRS89 LCC grid with 240 columns and 220 rows\n1\n\n\ntas\nDaily Mean Air Temperature\nc(240, 220, 365)\n\n\nnumber_of_stations\nNumber Of Stations Available For Interpolation Per Day All Over The HYRAS Area\n365"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#sec-vars",
    "href": "blog/posts/opening-nc-files/index.html#sec-vars",
    "title": "Opening .nc files",
    "section": "Time and spatial layers",
    "text": "Time and spatial layers\nWeâ€™re definitely going to need something along the lines of latitude and longitude. From the descriptions, we can see that lat and lon describe the cell center, and their dimension is 240 \\(\\times\\) 220. That is not what we need. Instead, we want something with dimensions of 1â€“2 \\(\\times\\) 240 or 220, which describes the latitude and longitude in general, not for every cell center. In this case, that applies for x_bnds and y_bnds.\nWe also need something specifying the time. In this case, that is time_bnds.\nLetâ€™s also get the crs for good measure, crs_HYRAS. This only has dimension 1, so we need to extract is as an attribute.\nAll of these layers can be named differently in different files, so it pays off to check out the specific name. Letâ€™s save them into variables so we canâ€™t forget them!\n\ntime &lt;- ncvar_get(raster, \"time_bnds\")\nlon &lt;- ncvar_get(raster, \"x_bnds\")\nlat &lt;- ncvar_get(raster, \"y_bnds\")\ncrs &lt;- ncatt_get(raster, \"crs_HYRAS\")$epsg_code"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#variable-layer",
    "href": "blog/posts/opening-nc-files/index.html#variable-layer",
    "title": "Opening .nc files",
    "section": "Variable layer",
    "text": "Variable layer\nNow, we also need the actual variable weâ€™re looking for. In this case, itâ€™s tas (for mean daily temperature). We can see that the dimensions are the largest and match our geospatial and time dimensions: 240 (x_bnds) \\(\\times\\) 220 (y_bnds) \\(\\times\\) 365 (time_bnds).\nLetâ€™s get this variableâ€™s array out. Additionally, letâ€™s find out how the NAs are coded, and use that information to code them as NAs that R recognizes.\n\nvariable_array &lt;- ncvar_get(raster, \"tas\")\nfillvalue &lt;- ncatt_get(raster, \"tas\", \"_FillValue\")\n\n# set NA value\nvariable_array[variable_array == fillvalue$value] &lt;- NA"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#close-nc-file",
    "href": "blog/posts/opening-nc-files/index.html#close-nc-file",
    "title": "Opening .nc files",
    "section": "Close nc file",
    "text": "Close nc file\nNow we have all the information we need, yay! Letâ€™s not forget to close the .nc file again.\n\nnc_close(raster)"
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#making-a-raster",
    "href": "blog/posts/opening-nc-files/index.html#making-a-raster",
    "title": "Opening .nc files",
    "section": "Making a raster",
    "text": "Making a raster\nNext, we make a raster of this with the terra package. We already know the structure of the array, where time is the last layer. This does vary over different files though!\nWe declare the extent and the crs that we extracted in SectionÂ 2.2. Then, letâ€™s go ahead and plot it!\n\ngot_weather_array &lt;- variable_array[,, day_of_year]\ngot_weather_raster &lt;- got_weather_array |&gt; \n  terra::rast(extent = ext(min(lon),\n                             max(lon),\n                             min(lat),\n                             max(lat)),\n                crs = crs)\nplot(got_weather_raster)\n\n\n\n\n\n\n\n\nWell, this somewhat looks like Germany â€¦ but not quite yet. We need to mirror it and turn it by 90Â°."
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#transposing-the-raster",
    "href": "blog/posts/opening-nc-files/index.html#transposing-the-raster",
    "title": "Opening .nc files",
    "section": "Transposing the raster",
    "text": "Transposing the raster\nFor this, we need to go back to the last step, and transpose the 2-dimensional array for our specific day. Then, we make it a raster again.\n\ngot_weather_raster_transposed &lt;- got_weather_array |&gt;\n  t() |&gt;\n  terra::rast(extent = ext(min(lon),\n                           max(lon),\n                           min(lat),\n                           max(lat)),\n              crs = crs)\n\ngot_weather_raster_transposed |&gt; \n  plot()\n\n\n\n\n\n\n\n\nWell, this is almost right â€“ we just need to turn it upside down now."
  },
  {
    "objectID": "blog/posts/opening-nc-files/index.html#flipping-the-raster",
    "href": "blog/posts/opening-nc-files/index.html#flipping-the-raster",
    "title": "Opening .nc files",
    "section": "Flipping the raster",
    "text": "Flipping the raster\nFor this task, terra has a specific function, flip. We can say which way to flip the raster â€“ in this case, vertically. Letâ€™s go ahead and plot this again.\n\ngot_weather_raster_right_side_up &lt;- got_weather_raster_transposed |&gt; \n  flip(direction = \"vertical\")\n\ngot_weather_raster_right_side_up |&gt; plot()\n\n\n\n\n\n\n\n\nAnd there we have it!"
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html",
    "href": "blog/posts/creating-a-basic-map/index.html",
    "title": "Creating a map with ggplot2",
    "section": "",
    "text": "In this post, I create a basic world map â€“ specifically, a Choropleth map. That means we colour the countries by a specific variable."
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html#basic-map",
    "href": "blog/posts/creating-a-basic-map/index.html#basic-map",
    "title": "Creating a map with ggplot2",
    "section": "Basic map",
    "text": "Basic map\nWe can simply do this with ggplot, with the function geom_sf. It takes normal aesthetics, so we can just hand it our variable of interest â€“ is_my_country. Since this is a map, it makes the most sense to just fill the polygons according to this variable, so we use the fill aesthetic.\n\nggplot() +\n  # plot an sf object\n  geom_sf(data = world,\n          # fill it according to my variable\n          aes(fill = is_my_country))\n\n\n\n\n\n\n\nFigureÂ 1: Choropleth map of my countries â€“ basic"
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html#intermediate-map",
    "href": "blog/posts/creating-a-basic-map/index.html#intermediate-map",
    "title": "Creating a map with ggplot2",
    "section": "Intermediate map",
    "text": "Intermediate map\nWe now decrease some of the clutter. We get rid of the legend since itâ€™s just a Boolean â€“ we can indicate this in our title/caption. We also choose different colours, and get rid of the gridlines.\n\nggplot() +\n  # plot an sf object\n  geom_sf(data = world,\n          # fill it according to my variable\n          aes(fill = is_my_country),\n         # don't show the legend: it's just true or false, can be shown in title\n          show.legend = FALSE) +\n  # make colours prettier\n  scale_fill_manual(values = c(\"white\", \"wheat\")) +\n  # remove clutter\n  theme_void() \n\n\n\n\n\n\n\nFigureÂ 2: Choropleth map of my countries (in yellow) â€“ intermediate"
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html#prettier-map",
    "href": "blog/posts/creating-a-basic-map/index.html#prettier-map",
    "title": "Creating a map with ggplot2",
    "section": "Prettier map",
    "text": "Prettier map\nIt doesnâ€™t quite look like weâ€™re used to, though. Check out the comments to see what weâ€™ve changed.\n\nggplot() +\n  # plot an sf object\n  geom_sf(\n    data = world,\n    # fill it according to my variable\n    aes(fill = is_my_country),\n    # make borders lighter\n    col = \"grey80\",\n    # don't show the legend: it's just true or false, can be shown in title\n    show.legend = FALSE\n  ) +\n  # add country labels\n  geom_sf_text(\n    # get the data just for the countries we want to show\n    data = world |&gt; filter(is_my_country == TRUE),\n    # get the sovereignt label, and transform it to upper case\n    aes(label = admin |&gt; toupper()),\n    # make it not as dark\n    col = \"grey30\",\n    # decrease size\n    size = 2.5\n  ) +\n  # make colours prettier\n  scale_fill_manual(values = c(\"white\", \"wheat\")) +\n  # change to a nicer projection: equal area (more accurate)\n  coord_sf(crs = \"ESRI:54009\") +\n  # remove clutter\n  theme_void()\n\n\n\n\n\n\n\nFigureÂ 3: Choropleth map of my countries â€“ prettier version"
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html#prettier-map-with-ocean",
    "href": "blog/posts/creating-a-basic-map/index.html#prettier-map-with-ocean",
    "title": "Creating a map with ggplot2",
    "section": "Prettier map with ocean",
    "text": "Prettier map with ocean\nThereâ€™s just some lines of code you need to add to have a round earth/rounded sea. We need to create a polygon that has just the shape of the earth. We can do this with st_graticule, and then st_cast it to a polygon. Then, we can simply plot this polygon at the beginning of our ggplot.\n\ngrat &lt;- st_graticule() |&gt; st_cast('POLYGON')\n\nggplot() +\n  # this is the new line\n  geom_sf(data = grat, fill = \"#d7ecfa\", col = \"#d7ecfa\") +\n  # now everything is the same as before\n  geom_sf(\n    data = world,\n    aes(fill = is_my_country),\n    col = \"grey80\",\n    show.legend = FALSE\n  ) +\n  # add country labels\n  geom_sf_text(\n    data = world |&gt; filter(is_my_country == TRUE),\n    aes(label = admin |&gt; toupper()),\n    col = \"grey30\",\n    size = 2.5\n  ) +\n  # make colours prettier\n  scale_fill_manual(values = c(\"white\", \"wheat\")) +\n  # change to a nicer projection: equal area (more accurate)\n  coord_sf(crs = \"ESRI:54009\") +\n  # remove clutter\n  theme_void()\n\n\n\n\n\n\n\nFigureÂ 4: Choropleth map of my countries â€“ round earth"
  },
  {
    "objectID": "blog/posts/creating-a-basic-map/index.html#advanced-stuff",
    "href": "blog/posts/creating-a-basic-map/index.html#advanced-stuff",
    "title": "Creating a map with ggplot2",
    "section": "Advanced stuff",
    "text": "Advanced stuff\nIf youâ€™re really interested, you can check out the following on top:\n\ngraticules (latitude/longitude)\nNorth arrow (not recommended for world maps, though)\nscale (not recommended for most world maps, though)"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "This blog is for people just starting out with their R journey. Iâ€™ll address beginner problems, simplifying some concepts in R programming.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a locator map with ggplot2\n\n\n\n\n\n\ncode\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nFeb 2, 2025\n\n\nSarah Zeller\n\n\n\n\n\n\n\n\n\n\n\n\nOpening .kmz files\n\n\n\n\n\n\ncode\n\n\nspatial formats\n\n\n\n\n\n\n\n\n\nMay 27, 2024\n\n\nSarah Zeller\n\n\n\n\n\n\n\n\n\n\n\n\nReading a csv file with 2-row column names\n\n\n\n\n\n\ncode\n\n\ndata\n\n\n\nSometimes, csv files have 2-row column names. I create a function to deal with this.\n\n\n\n\n\nMay 5, 2024\n\n\nSarah Zeller\n\n\n\n\n\n\n\n\n\n\n\n\nOpening .nc files\n\n\n\n\n\n\ncode\n\n\nspatial formats\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n\nSarah Zeller\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a map with ggplot2\n\n\n\n\n\n\ncode\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\nSarah Zeller\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a basic regression table with modelsummary\n\n\n\n\n\n\ncode\n\n\nsummary\n\n\n\n\n\n\n\n\n\nNov 28, 2023\n\n\nSarah Zeller\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/opening-kmz-files/index.html",
    "href": "blog/posts/opening-kmz-files/index.html",
    "title": "Opening .kmz files",
    "section": "",
    "text": "When working with spatial data, one thing Iâ€™ve noticed is: thereâ€™s a lot of obscure data formats. And with every one of them, it takes me a while to figure out how to handle them in R. So I decided to make a series of blog posts on how to handle some of the spatial formats Iâ€™ve come across.\nThis post is on .kmz files. If youâ€™re working with Google Earth Pro, this is the format your vector files will be exported in. Recently, Iâ€™ve worked quite a bit with Google Earth Pro to collect data on landfills by hand. Youâ€™ll find an example .kmz file here."
  },
  {
    "objectID": "blog/posts/opening-kmz-files/index.html#extracting-information-from-the-name",
    "href": "blog/posts/opening-kmz-files/index.html#extracting-information-from-the-name",
    "title": "Opening .kmz files",
    "section": "Extracting information from the Name",
    "text": "Extracting information from the Name\nWhen we check out our agbogbloshie_polygon data frame, we can see that thereâ€™s information contained in the Name column, specifically: the year for which the polygon shape is valid. So letâ€™s extract that numeric information from the character column! Because the description is quite long and has much information included â€“ and itâ€™s always formatted the same way â€“, weâ€™ll use the unglue package to extract the information. Also, the landfill is misspelt in some cases, so we need to account for that.\n\nagbogbloshie_polygon &lt;- agbogbloshie_polygon |&gt; \n  unglue_unnest(Name, \n                patterns = c(\"{landfill_name}_{month}_{year}_{polygon_no}\",\n                             \"{landfill_name}_{month}_{year}\",\n                             \"{landfill_name} {month}_{year}\"),\n                remove = FALSE) |&gt; \n  mutate(landfill_name = case_match(landfill_name,\n                                    \"Agblogbloshie\" ~ \"Agbogbloshie\",\n                                    \"Agbogbgloshie\" ~ \"Agbogbloshie\",\n                                    .default = \"Agbogbloshie\"))\n\nagbogbloshie_polygon\n\nSimple feature collection with 8 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XYZ\nBounding box:  xmin: -0.2311228 ymin: 5.54208 xmax: -0.2246721 ymax: 5.556922\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n# A tibble: 8 Ã— 7\n  Name                     Description landfill_name month year  polygon_no\n* &lt;chr&gt;                    &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     \n1 Agbogbloshie_02_2020     \"\"          Agbogbloshie  02    2020  &lt;NA&gt;      \n2 Agbogbloshie_10_2018     \"\"          Agbogbloshie  10    2018  &lt;NA&gt;      \n3 Agblogbloshie 10_2016    \"\"          Agbogbloshie  10    2016  &lt;NA&gt;      \n4 Agbogbloshie_10_2018_02  \"\"          Agbogbloshie  10    2018  02        \n5 Agbogbloshie_10_2018_03  \"\"          Agbogbloshie  10    2018  03        \n6 Agbogbgloshie_02_2020_02 \"\"          Agbogbloshie  02    2020  02        \n7 Agbogbloshie_02_2020_03  \"\"          Agbogbloshie  02    2020  03        \n8 Agbogbloshie_10_2016_02  \"\"          Agbogbloshie  10    2016  02        \n# â„¹ 1 more variable: geometry &lt;MULTIPOLYGON [Â°]&gt;\n\n\nLetâ€™s use this information to plot the landfill in the two different years! Seems like the landfill grew quite a bit in between.\n\nggplot() +\n  geom_sf(data = agbogbloshie_polygon) +\n  facet_wrap(~year) +\n  geom_sf(data = agbogbloshie_point) +\n  theme_void() +\n  ggspatial::annotation_scale()\n\n\n\n\n\n\n\nFigureÂ 1: Agbogbloshie landfill over time\n\n\n\n\n\nThis looks good! However, we can see that the landfills consist of multiple polygons. Letâ€™s get them together."
  },
  {
    "objectID": "blog/posts/opening-kmz-files/index.html#summarizing-into-one-polygon",
    "href": "blog/posts/opening-kmz-files/index.html#summarizing-into-one-polygon",
    "title": "Opening .kmz files",
    "section": "Summarizing into one polygon",
    "text": "Summarizing into one polygon\nIn every year, we have more than one polygon. We want to collapse these into a single multipolygon. For that, we need to summarize them by year and landfill.\n\nagbogbloshie_polygon &lt;- agbogbloshie_polygon |&gt; \n  st_zm() |&gt; \n  st_transform(crs = \"ESRI:54009\") |&gt; \n  st_make_valid() |&gt; \n  # summarize geometry into multipolygons\n  group_by(landfill_name, year, month) |&gt; \n  summarize() |&gt; \n  ungroup()"
  },
  {
    "objectID": "blog/posts/opening-kmz-files/index.html#calculating-area",
    "href": "blog/posts/opening-kmz-files/index.html#calculating-area",
    "title": "Opening .kmz files",
    "section": "Calculating area",
    "text": "Calculating area\nAs a next step, letâ€™s calculate the area of these polygons. After all, itâ€™s interesting to see if this landfill shrinks or grows!\nFor now, our data are unprojected, though. We can check this by getting the coordinate reference system (CRS) of our data. The output is very long and includes a lot of information, but we only need to focus on the first line, the User input. The next lines show the corresponding well-known text (wkt), which details exactly how the CRS works. We can see here that the CRS is still WGS 84, which means â€“ unprojected.\n\nst_crs(agbogbloshie)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nHowever, we know that the world is shaped like a potato, and that these unprojected data are biased. To correct for this, we first need to project the data into a CRS thatâ€™s accurate for that world region when it comes to area â€“ we also call this area-preserving projection. The official CRS for Ghana, where this landfill is located, has the EPSG code 2136. Once weâ€™ve projected the polygons, we can easily calculate the area with the sf package.\n\nagbogbloshie_polygon &lt;- agbogbloshie_polygon |&gt; \n  st_transform(crs = \"epsg:2136\") |&gt; \n  mutate(area = st_area(geometry)) \n\nagbogbloshie_polygon\n\nSimple feature collection with 3 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1179342 ymin: 316685.8 xmax: 1181692 ymax: 322068\nProjected CRS: Accra / Ghana National Grid\n# A tibble: 3 Ã— 5\n  landfill_name year  month                                      geometry   area\n* &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;                                &lt;MULTIPOLYGON&gt;  [m^2]\n1 Agbogbloshie  2016  10    (((1180085 320017.8, 1180468 319802.8, 11805â€¦ 2.41e5\n2 Agbogbloshie  2018  10    (((1180357 319898.9, 1180372 319891.8, 11803â€¦ 2.94e5\n3 Agbogbloshie  2020  02    (((1179921 320055.5, 1179936 320041.3, 11799â€¦ 2.56e5\n\n\nYouâ€™ll notice that the area column has a specific format: itâ€™s a unit. This package makes it easy to convert values from one unit into another. Letâ€™s see how we can convert the area into hectares. Afterwards, letâ€™s drop the unit because we have the data in the final shape we want them.\n\nagbogbloshie_polygon &lt;- agbogbloshie_polygon |&gt; \n  mutate(area_ha = set_units(area, \"ha\") |&gt; drop_units())\n\nAnd there we have it, a data frame with the attributes that we need! Letâ€™s check out the area in comparison. We see that thereâ€™s not that much difference!\n\nggplot(data = agbogbloshie_polygon) +\n  geom_col(aes(x = year |&gt; as.character(), y = area_ha)) +\n  coord_flip() +\n  labs(y = \"Area (ha)\",\n       x = \"\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigureÂ 2: Agbogbloshie landfill area over time"
  },
  {
    "objectID": "blog/posts/locator-map/index.html",
    "href": "blog/posts/locator-map/index.html",
    "title": "Creating a locator map with ggplot2",
    "section": "",
    "text": "Sometimes I visualize data on a country that not everyone is familiar with. In this case, a locator map can be helpful: It shows where in the world my country of interest is. Here, Iâ€™ll show you how to create such a locator map for Ghana."
  },
  {
    "objectID": "blog/posts/locator-map/index.html#plotting-the-graticule",
    "href": "blog/posts/locator-map/index.html#plotting-the-graticule",
    "title": "Creating a locator map with ggplot2",
    "section": "Plotting the graticule",
    "text": "Plotting the graticule\nLetâ€™s start out with just plotting our graticule. Thatâ€™s the net of lines that make up the latitudes and longitudes, and that weâ€™re used to seeing from a gobe. For that, weâ€™ll need:\n\na graticule\nthe projection\na theme_void()\n\n\n\n\n\n\n\nTip\n\n\n\nTechnically, you can also simply use the ggplot gridlines. However, theyâ€™re a bit buggy, so Iâ€™d recommend using these explicit gridlines. Thatâ€™s why weâ€™re also using the theme_void(): so we donâ€™t get those gridlines as well.\n\n\nWe can use the function sf::st_graticule to create this graticule on the fly.\n\nglobe &lt;- ggplot() +\n  # define our graticules\n  geom_sf(data = st_graticule(n_discr = 1),\n          col = \"grey80\", fill = \"white\", linewidth = .25) +\n  # define the CRS and theme\n  coord_sf(crs = locator_crs) +\n  theme_void() \n\nglobe\n\n\n\n\n\n\n\n\nAnd ta-da, thatâ€™s our globe!"
  },
  {
    "objectID": "blog/posts/locator-map/index.html#plotting-the-world",
    "href": "blog/posts/locator-map/index.html#plotting-the-world",
    "title": "Creating a locator map with ggplot2",
    "section": "Plotting the world",
    "text": "Plotting the world\nLetâ€™s continue with plotting the world on top, so we have some context for locating. Weâ€™ll plot the world in a grey tone, since we only need it for context, but donâ€™t want the map reader to be overwhelmed.\nWeâ€™ll need:\n\na world sf dataset\nour CRS (again)\n\nSince weâ€™re using the Natural Earth dataset, weâ€™ll give credit to them through the caption.\n\n\n\n\n\n\nTip\n\n\n\nWe need to define the CRS again because weâ€™re calling a geometry (geom_sf()) after we last defined the CRS.\n\n\n\nlocator_map &lt;- globe +\n  geom_sf(data = world,\n          col = \"grey85\") +\n  # define the CRS\n  coord_sf(crs = locator_crs) +\n  # give credit\n  labs(caption = \"Data: Natural Earth\")\n\nlocator_map"
  },
  {
    "objectID": "blog/posts/locator-map/index.html#highlighting-our-country",
    "href": "blog/posts/locator-map/index.html#highlighting-our-country",
    "title": "Creating a locator map with ggplot2",
    "section": "Highlighting our country",
    "text": "Highlighting our country\nNow letâ€™s get to the interesting part: highlighting!\n\nHighlighting by color\nWith countries that are large enough, simply highlighting by color works well. We give the country any other color than grey, and itâ€™s going to pop.\nSo what do we need?\n\nour countryâ€™s geometry\na highlighting color (Iâ€™m choosing white)\nour CRS (again)\n\nWeâ€™re starting with our last map, and add just our country on top.\n\nlocator_map +\n  # define our country\n  geom_sf(data = world |&gt; filter(sovereignt == \"Ghana\"),\n          fill = \"#1EB53A\",\n          col = \"grey85\") +\n  # make sure we have the correct CRS\n  coord_sf(crs = locator_crs) \n\n\n\n\n\n\n\n\n\n\nHighlighting with a dot\nSometimes, we donâ€™t want to highlight a whole country, but instead just a smaller spot â€“ maybe\n\na city,\na mountain or\na tree that we find interesting.\n\nIn this case, it makes sense to use a point geometry for highlighting. So weâ€™ll need\n\na point geometry\nour CRS (again)\n\n\n# make Ghana a point geometry\nghana_dot &lt;- world |&gt; \n  filter(sovereignt == \"Ghana\") |&gt; \n  st_centroid()\n\nlocator_map +\n  geom_sf(data = ghana_dot) +\n  # make sure we have the correct CRS\n  coord_sf(crs = locator_crs) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nHere, we donâ€™t have to define a color â€“ having one point already pops.\n\n\n\n\nHighlighting with a bounding box\nSometimes, we want to highlight a larger area that wouldnâ€™t show well on a globe: maybe an island group or a small country. In this case, we can also highlight using a bounding box of our original geometry.\nSo letâ€™s start by creating our bounding box for the geometry. Importantly, it needs to be a polygon so we can plot it.\n\n\n\n\n\n\nTip\n\n\n\nMake sure you transform your polygonâ€™s CRS to the one youâ€™ll be using for the locator map. Otherwise, the bounding box wonâ€™t be rectangular.\n\n\n\nghana_bbox &lt;- world |&gt; \n  filter(sovereignt == \"Ghana\") |&gt; \n  st_transform(locator_crs) |&gt; \n  st_bbox() |&gt; \n  st_as_sfc()\n\nggplot() +\n  geom_sf(data = ghana_bbox) +\n  coord_sf(crs = locator_crs)\n\n\n\n\n\n\n\n\nIf we plot it, we can see itâ€™s just a rectangle. And itâ€™s got 90Â° angles when using our locator map CRS. Perfect, so letâ€™s plot it on top of our raw locator map! Letâ€™s make sure that we buffer the bounding box a bit â€“ that way, we can see the borders of our country. Setting fill to NA makes sure that we can see whatâ€™s below the bounding box.\n\nlocator_map +\n  geom_sf(data = ghana_bbox |&gt; st_buffer(5e4),\n          fill = NA,\n          lwd = .5) +\n  # make sure we have the correct CRS\n  coord_sf(crs = locator_crs) \n\n\n\n\n\n\n\n\nAnd there we go: three different ways of creating a locator map. If you want to combine it with your more detailed map into a single plot, Iâ€™d recommend the package patchwork for this."
  },
  {
    "objectID": "blog/posts/showing-regression-results/index.html",
    "href": "blog/posts/showing-regression-results/index.html",
    "title": "Creating a basic regression table with modelsummary",
    "section": "",
    "text": "In this post, we have a look at creating a basic regression table with modelsummary and fixest."
  },
  {
    "objectID": "blog/posts/showing-regression-results/index.html#basic-table",
    "href": "blog/posts/showing-regression-results/index.html#basic-table",
    "title": "Creating a basic regression table with modelsummary",
    "section": "Basic table",
    "text": "Basic table\nCreating a summary table of our equations is very straight-forward with modelsummary: We create a list of the models we want to show, and then input that to modelsummary.\n\nlist(gravity_ols,\n     gravity_pois) |&gt;\n  modelsummary()\n\n\n\nTableÂ 1: Some regressions â€“ basic\n\n\n\n\n\n\n\nÂ (1)\nÂ Â (2)\n\n\n\n\nlog_dist_km\n-47643.024\n-0.002\n\n\n\n(10905.572)\n(0.000)\n\n\nNum.Obs.\n38325\n38325\n\n\nR2\n0.286\n0.751\n\n\nR2 Adj.\n0.285\n0.751\n\n\nR2 Within\n0.031\n0.269\n\n\nR2 Within Adj.\n0.031\n0.269\n\n\nAIC\n1533832.6\n1e+12\n\n\nBIC\n1534328.7\n1e+12\n\n\nRMSE\n118498460.83\n88327120.62\n\n\nStd.Errors\nby: Origin\nby: Origin\n\n\nFE: Origin\nX\nX\n\n\nFE: Destination\nX\nX\n\n\nFE: Product\nX\nX\n\n\nFE: Year\nX\nX"
  },
  {
    "objectID": "blog/posts/showing-regression-results/index.html#prettier-table",
    "href": "blog/posts/showing-regression-results/index.html#prettier-table",
    "title": "Creating a basic regression table with modelsummary",
    "section": "Prettier table",
    "text": "Prettier table\nHowever, the output in TableÂ 1 is not very pretty yet. Itâ€™s not entirely clear yet what the independent variable is, we donâ€™t know what (1) and (2) stand for, and we have a mass of goodness-of-fit measures. Letâ€™s customize our table!\nAs a first step, we make create some helper functions. These help with formatting the table.\n\n\nCode\n# format numbers: thousand separator\nf &lt;- function(x, n_digits = 2) {\n  ifelse(is.na(x),\n         \"\",\n         formatC(\n           x,\n           digits = n_digits,\n           big.mark = \",\",\n           format = \"f\"\n         ))\n}\n\nf_0 &lt;- purrr::partial(f, n_digits = 0)\n  \n#  function for GOF measures we don't want to change\nkeep_format &lt;- function(x) list(\"raw\" = x, \"clean\" = x, \"fmt\" = NA)\n\n\nThen, we create a list where we format our goodness-of-fit (GOF) measures. Some of the default names are not so pretty, e.g.Â Num.Observations without a space between the two words â€“ so we switch them to shorter or nicer names.\n\n\nCode\n# format # observations and R^2, keep the rest\ngof_tidy &lt;- list(\n  list(\n    \"raw\" = \"nobs\",\n    \"clean\" = \"Observations\",\n    \"fmt\" = f_0\n  ),\n  list(\n    \"raw\" = \"r.squared\",\n    \"clean\" = \"R\\u00B2\",\n    \"fmt\" = 3\n  ),\n  keep_format(\"FE: Origin\"),\n  keep_format(\"FE: Destination\"),\n  keep_format(\"FE: Product\"),\n  keep_format(\"FE: Year\")\n)\n\n\nLetâ€™s change the labels for our regression. We do this by adding names to the listâ€™s input (lines 1â€“2).\nAs a next step, letâ€™s use the label we added earlier on, by setting coef_rename to true. Letâ€™s also format the numbers using the formatting function we set up earlier, f.\nLetâ€™s omit some of the goodnes-of-fit (gof) indicators, since we donâ€™t need all of them here. We do this with the gof_map argument, to which we supply our GOF list from the last step. Alternatively, we could use a regex in the gof_omit argument: anything that matches the expression in line 4 will not be included.\nAlso, Iâ€™m used to adding stars where a coefficient is significant. This is not added by default, so letâ€™s simply set the stars argument to true.\nThen, weâ€™re setting the output to gt, which gives us the possibility to further style the table with the package gt. We add a header detailing our dependent variable. Then, we add a spanner to tell readers that OLS and Poisson are regression models.\n\nlist(OLS = gravity_ols,\n     Poisson = gravity_pois) |&gt;\n  modelsummary(\n    coef_rename = TRUE,\n    gof_map = gof_tidy,\n    fmt = f,\n    stars = TRUE,\n    output = \"gt\"\n  ) |&gt;\n  # add header and spanner\n  tab_header(title = \"Dependent variable: Trade flow [â‚¬]\") |&gt;\n  tab_spanner(\n    label = \"Regression model\",\n    columns = c(\"OLS\", \"Poisson\")\n    )\n\n\n\nTableÂ 2: Some regressions â€“ prettier\n\n\n\n\n\n\n\n\n\nDependent variable: Trade flow [â‚¬]\n\n\n\nRegression model\n\n\nOLS\nPoisson\n\n\n\n\nLog (distance [km])\n-47,643.02***\n-0.00***\n\n\n\n(10,905.57)\n(0.00)\n\n\nObservations\n38,325\n38,325\n\n\nRÂ²\n0.286\n0.751\n\n\nFE: Origin\nX\nX\n\n\nFE: Destination\nX\nX\n\n\nFE: Product\nX\nX\n\n\nFE: Year\nX\nX\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sarah Zeller",
    "section": "",
    "text": "Iâ€™m a PhD student at the Technical University of Dresden (TUD) in Germany, specializing in data science with a focus on data visualization. My academic work revolves around exploring and interpreting complex datasets to uncover new insights. I primarily code in R, a language and environment that I find well-suited for statistical analysis and graphical techniques in my research.\nI have a particular interest in the challenge of data wrangling â€“ organizing, cleaning, and transforming raw data into a usable format for analysis. This crucial step in the research process allows me to delve deep into the data, uncovering patterns and trends that might otherwise remain hidden.\nOne of my key strengths is in creating clear, compelling visuals to present my findings. I believe that good visualizations are essential for effectively communicating complex data insights."
  }
]